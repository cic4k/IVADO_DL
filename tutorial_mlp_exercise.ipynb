{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial mlp - exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cic4k/IVADO_DL/blob/master/tutorial_mlp_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mipSoOVlavkb"
      },
      "source": [
        "# IVADO/MILA DEEP LEARNING SCHOOL\n",
        "# 4th edition (Fall 2019)\n",
        "# Tutorial : Categorical data with multilayer perceptron (MLP)\n",
        "\n",
        "## Authors: \n",
        "\n",
        "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
        "\n",
        "Gaétan Marceau Caron <gaetan.marceau.caron@mila.quebec>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GByD5vFakF5Z",
        "colab_type": "code",
        "outputId": "7d867fe5-4d5c-4fca-e77d-e0a87e3cee74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sLHwvggEZERd"
      },
      "source": [
        "## Preface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JKNGtQkkohiM"
      },
      "source": [
        "This tutorial introduces the practical aspects of Deep Learning through the realization of a simple end-to-end project. We will use the deep learning library <a href=\"https://pytorch.org/\"> `PyTorch`</a>, which is well-known for its ease of use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NOD70vdvvtin"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq9FwFVnQihX",
        "colab_type": "text"
      },
      "source": [
        "## Loading packages and using GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reCpBfp1Qcrt",
        "colab_type": "text"
      },
      "source": [
        "Before we start, we install the necessary packages for the tutorial by using pip. To do this, execute the following cell by selecting it and using `shift+Enter`. This step may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c5AlBPjnvzNh",
        "outputId": "0a988f57-9b66-4389-efa3-4d402961739e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip3 install 'torch==1.1.0' 'torchvision==0.3.0' 'Pillow==4.3.0' 'matplotlib==3.0.3'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision==0.3.0 in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: Pillow==4.3.0 in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: matplotlib==3.0.3 in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.3.0) (0.46)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "djF9gjzLwsDB"
      },
      "source": [
        "Now, import all the modules we will use for this tutorial by running the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9LnNnxBw0wC",
        "outputId": "e2277594-92b2-43de-8440-b104f10c0d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed) # Set the random seed of numpy for the data split.\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "\n",
        "print(\"Torch version: \", torch.__version__)\n",
        "print(\"GPU Available: {}\".format(use_gpu))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version:  1.1.0\n",
            "GPU Available: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZKzgFV9Favkt"
      },
      "source": [
        "## PyTorch in a nutshell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vrus_-F0avkt"
      },
      "source": [
        "*PyTorch* is a Python library that supports a vibrant ecosystem of tools and libraries for ML in vision, NLP, and more. It provides two high-level features:\n",
        "<ul>\n",
        "<li> operations on <a href=\"https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\">tensors</a> (such as NumPy) with GPU support,</li>\n",
        "<li> operations for creating and optimizing computational graphs with an automatic differentiation system called <a href=\"https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py\">Autograd</a>.</li>\n",
        "</ul>\n",
        "\n",
        "<a href=\"https://pytorch.org/docs/stable/torch.html\">PyTorch docs</a> contain the API documentation and <a href=\"https://pytorch.org/tutorials/\">many tutorials</a>.\n",
        "Also, PyTorch offers several data processing utilities. One of these utilities is the class <a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.Dataset`</a> which offers an easy to use interface to handle a data set. For more information, please refer to the following urls: \n",
        "<ul>\n",
        "<li>PyTorch data sets: <a href=\"http://pytorch.org/docs/master/data.html\"> PyTorch - datasets</a>.</li>\n",
        "<li>A tutorial for loading data: <a href=\"http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"> PyTorch - data loading tutorial</a>.</li>\n",
        "</ul>\n",
        "\n",
        "<a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> is a package that provides the same functions as CPU tensors but for  CUDA tensors, which are used for GPU computing. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> returns a boolean indicating if CUDA is currently available. Finally, we recommend using a `device` variable that identifies the device on which you want to perform computations. We can assign a tensor to a device with the method `.to(device)`. By default, the tensors are CPU tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qm122vNmq92L"
      },
      "source": [
        "## Ingredients for a proof of concept (POC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nqvhR0ebavmE"
      },
      "source": [
        "To realize a ML POC, you need:\n",
        "<ul>\n",
        "<li>a task description as well as data to support it,</li>\n",
        "<li>an evaluation metric to assess the performance of a model,</li>\n",
        "<li>a model description,</li>\n",
        "<li>a cost function to be optimized,</li>\n",
        "<li>an optimizer that adjusts the parameters of the model.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y8_pfpu2f6AO"
      },
      "source": [
        "# How to prepare the dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B5piZxYUhSzq"
      },
      "source": [
        "Our task is to predict whether or not a passenger survived the sinking of the Titanic based on passenger data only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y4GuYNDFavlU"
      },
      "source": [
        "## Titanic dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NiOJx2ytavlU"
      },
      "source": [
        "We can download the Titanic dataset at the following address: https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true.<br/>\n",
        "This dataset provides information on the fate of 1309 passengers of the first and only journey of the liner \"RMS Titanic\", summarized by economic status (class), gender, age, family information, and survival. The Kaggle platform also uses this dataset as an introduction to classical machine learning. Here, we use it to introduce more advanced concepts related to PyTorch and Deep Learning.\n",
        "\n",
        "We use the library <a href=\"https://pandas.pydata.org/\">Pandas</a> to load the dataset into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bX_RSiffavlW",
        "outputId": "170fc944-f33f-468a-f3d8-2c01174c76c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "titanic_df = pd.read_csv(\n",
        "    'https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true', \n",
        "    sep='\\t', \n",
        "    index_col=None, \n",
        "    na_values=['NA']\n",
        ")\n",
        "\n",
        "# a snapshot of the first 5 data points\n",
        "titanic_df.head()\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "      <th>name</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>ticket</th>\n",
              "      <th>fare</th>\n",
              "      <th>cabin</th>\n",
              "      <th>embarked</th>\n",
              "      <th>boat</th>\n",
              "      <th>body</th>\n",
              "      <th>home.dest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Allen, Miss. Elisabeth Walton</td>\n",
              "      <td>female</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24160</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>B5</td>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>St Louis, MO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Allison, Master. Hudson Trevor</td>\n",
              "      <td>male</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Miss. Helen Loraine</td>\n",
              "      <td>female</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>135.0</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
              "      <td>female</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pclass  survived  ...   body                        home.dest\n",
              "0       1         1  ...    NaN                     St Louis, MO\n",
              "1       1         1  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "2       1         0  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "3       1         0  ...  135.0  Montreal, PQ / Chesterville, ON\n",
              "4       1         0  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yj88WmCmavlf"
      },
      "source": [
        "**The meaning of the different columns (features) is as follows**:\n",
        "\n",
        "<ol>\n",
        "\n",
        "  <li> <b>pclass</b>: Passenger class (1 = first; 2 = second; 3 = third) </li>\n",
        "  <li> <b>survived</b>: Survived? (0 = no; 1 = yes) </li>\n",
        "  <li> <b>name</b>: Name </li>\n",
        "  <li> <b>sex</b>: Sex </li>\n",
        "  <li> <b>age</b>: Age </li>\n",
        "  <li> <b>sibsp</b>: Number of brothers, sisters, or spouses onboard </li>\n",
        "  <li> <b>parch</b>: Number of parents or children onboard </li>\n",
        "  <li> <b>ticket</b>: Ticket number </li>\n",
        "  <li> <b>fare</b>: Passenger fare </li>\n",
        "  <li> <b>cabin</b>: Cabin number </li>\n",
        "  <li> <b>embarked</b>: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton) </li>\n",
        "  <li> <b>boat</b>: Lifeboat (if the passenger survived) </li>\n",
        "  <li> <b>body</b>: Body number (if the passenger did not survive and his body was found) </li>\n",
        "  <li> <b>home.dest</b>: the passenger's destination </li>\n",
        " </ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u2ed5fozqjce"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__vcZhPnavlg"
      },
      "source": [
        "### Feature selection\n",
        "Some features are not relevant to the task, for example:\n",
        "<ol>\n",
        "  <li> <b>name</b>: Name </li>\n",
        "  <li> <b>ticket</b>: Ticket number </li>\n",
        "  <li> <b>cabin</b>: Cabin number </li>\n",
        "  <li> <b>home.dest</b>: Passenger's destination </li>\n",
        " </ol>\n",
        " \n",
        "Other features give away the label to be predicted and including them would be cheating:\n",
        "<ol>\n",
        "  <li> <b>boat</b>: Lifeboat (if the passenger survived) </li>\n",
        "  <li> <b>body</b>: Body number (if the passenger did not survive and his body was found) </li>\n",
        " </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JJ0--SDpavlg",
        "outputId": "f3362103-0ec9-4312-f611-cda715b37f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "titanic_preprocess_df = pd.read_csv(\n",
        "    'https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true', \n",
        "    sep=',', \n",
        "    index_col=None\n",
        ")\n",
        "\n",
        "titanic_preprocess_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass_1</th>\n",
              "      <th>pclass_2</th>\n",
              "      <th>pclass_3</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked_C</th>\n",
              "      <th>embarked_Q</th>\n",
              "      <th>embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  pclass_1  pclass_2  ...  embarked_C  embarked_Q  embarked_S\n",
              "0         1         1         0  ...           0           0           1\n",
              "1         1         1         0  ...           0           0           1\n",
              "2         0         1         0  ...           0           0           1\n",
              "3         0         1         0  ...           0           0           1\n",
              "4         0         1         0  ...           0           0           1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MckYm0M_xhR",
        "colab_type": "text"
      },
      "source": [
        " ### Feature encoding\n",
        " \n",
        "Some features are **categorical variables**, which means that they can take a finite number of values.\n",
        " <ol>\n",
        "  <li> <b>pclass</b>: Passenger Class </li>\n",
        "  <li> <b>sex</b>: Sex </li>\n",
        "  <li> <b>embarked</b>: Port of embarkation </li>\n",
        " </ol>\n",
        "\n",
        "To process categorical variables, we need to encode them in a way that does not imply an arbitrary order such as using natural numbers (e.g., 1, 2, 3). <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">One-hot encoding</a> is a way to achieve it. We can download the pre-processed dataset at the following address: https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true.\n",
        "<br>The meaning of the encoded variables is as follows:\n",
        "\n",
        "<ol>\n",
        "  <li> <b>survived</b>: Survived? (0 = no; 1 = yes) </li>\n",
        "  <li> <b>pclass_1</b>: (1 if passenger in first class; 0 if not) </li>\n",
        "  <li> <b>pclass_2</b>: (1 if passenger in second class; 0 if not) </li>\n",
        "  <li> <b>pclass_3</b>: (1 if passenger in third class; 0 if not) </li>\n",
        "  <li> <b>sex_female</b>: (1 if passenger is female; 0 if not) </li>\n",
        "  <li> <b>sex_male</b>: (1 if passenger is male; 0 if not) </li>\n",
        "  <li> <b>age</b>: Age </li>\n",
        "  <li> <b>sibsp</b>: Number of brothers, sisters, or spouses onboard </li>\n",
        "  <li> <b>parch</b>: Number of parents or children onboard </li>\n",
        "  <li> <b>fare</b>: Passenger fare </li>\n",
        "  <li> <b>embarked_C</b>: (1 if Port of embarkation = Cherbourg (C); 0 otherwise) </li> \n",
        "  <li> <b>embarked_Q</b>: (1 if Port of embarkation = Queenstown (Q); 0 otherwise) </li> \n",
        "  <li> <b>embarked_S</b>: (1 if Port of embarkation = Southampton (S); 0 otherwise)</li> \n",
        " </ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJcs6PUTavlm"
      },
      "source": [
        "## Train / validation / test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bjbgvffmavlo"
      },
      "source": [
        "At this point, we need to divide the dataset into three subsets:\n",
        "\n",
        "<ol>\n",
        "<li> <b> Train</b> (usually 60% of the dataset): used to train the classification model. </li>   \n",
        "<li> <b> Validation</b> (generally 20% of the dataset): used to evaluate hyper-parameters on held-out data. </li>   \n",
        "<li> <b> Test</b> (usually 20% of the dataset): used to evaluate the generalization performance of the chosen model on held-out data. </li>\n",
        "</ol>\n",
        "\n",
        "We use the <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.split.html\">numpy.split function</a> to separate our dataset into subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBmL8VBOavlo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2d8f83c7-d638-42f4-8004-282ec23a1892"
      },
      "source": [
        "train, validate, test = np.split(\n",
        "    titanic_preprocess_df.sample(frac=1, random_state=seed), \n",
        "    [int(.6*len(titanic_preprocess_df)), int(.8*len(titanic_preprocess_df))])\n",
        "\"\"\"\n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html\n",
        "np.split(ndarray, indices_or_sections) <- ndarray to split in [] indices\n",
        "titanic_preprocess_df.sample() <- frac*100 random sample of the dataset with a \n",
        " random state equal to seed\n",
        "\"\"\"\n",
        "\n",
        "# Remove the label column from X and create a label vectors.\n",
        "X_train = train.drop(['survived'], axis=1).values\n",
        "y_train = train['survived'].values\n",
        "\n",
        "X_val = validate.drop(['survived'], axis=1).values\n",
        "y_val = validate['survived'].values\n",
        "\n",
        "X_test = test.drop(['survived'], axis=1).values\n",
        "y_test = test['survived'].values\n",
        "\n",
        "print(\"Number of training samples:\", len(y_train))\n",
        "print(\"Number of validating samples:\", len(y_val))\n",
        "print(\"Number of testing samples:\", len(y_test))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 625\n",
            "Number of validating samples: 209\n",
            "Number of testing samples: 209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wv74TbIWavlr"
      },
      "source": [
        "## Datasets in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9_LJtG-Xavlt"
      },
      "source": [
        "We will use the subclass <b><a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.TensorDataset`</a> </b> to manipulate together the features and targets of a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1JtT4tV7avlt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4257b720-96c0-4773-8d9e-2eefa841c518"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(),\n",
        "                              torch.from_numpy(y_train).long())\n",
        "\n",
        "val_dataset = TensorDataset(torch.from_numpy(X_val).float(),\n",
        "                              torch.from_numpy(y_val).long())\n",
        "\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(),\n",
        "                              torch.from_numpy(y_test).long())\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([ 1.0000,  0.0000,  0.0000,  1.0000,  0.0000, 45.0000,  1.0000,  0.0000,\n",
            "        52.5542,  0.0000,  0.0000,  1.0000]), tensor(1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85mG_k_Rjxwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0366b22c-9d4f-4fa5-ce40-5435064bc3de"
      },
      "source": [
        "print(train_dataset[0])\n",
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([ 0.,  1.,  0.,  1.,  0.,  2.,  1.,  1., 26.,  0.,  0.,  1.]), tensor(1))\n",
            "[ 0.  1.  0.  1.  0.  2.  1.  1. 26.  0.  0.  1.]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "obEPHnlTavkc"
      },
      "source": [
        "# How to define the learning algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qhN5GL6Gavks"
      },
      "source": [
        "A multilayer perceptron (MLP) is a simple computational graph composed of \"hidden layers,\" which are defined by two modules: a *linear transformation* followed by a *non-linearity*. The result of a hidden layer is a vector called *a distributed representation* where each component is associated with a hidden unit.\n",
        "\n",
        "To train this model, we need to define:\n",
        "<ul>\n",
        "<li>the network architecture by choosing the non-linear function and the number of hidden units per layer, </li>\n",
        "<li>the cost function and optimizer. </li>\n",
        "</ul>\n",
        "\n",
        "To solve our task, we will use a MLP with the following properties:\n",
        " <ul>\n",
        " <li> the input dimension of the model is 12,</li>\n",
        " <li> the output dimension of the model is 2,</li>\n",
        " <li> the first dimension of the output is the probability of death and the second dimension is the probability of survival,</li>\n",
        "  <li> the number of hidden layers is 3, </li>\n",
        " <li> the dimensions of the hidden layers are 20, 40, 20 respectively, </li>\n",
        " <li> the activation function is a ReLu for all hidden layers. </li>\n",
        " </ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "701t0e-ravkr"
      },
      "source": [
        "## How to define a model in PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m4F5cyijavkv"
      },
      "source": [
        "The <a href=\"https://pytorch.org/docs/stable/nn.html\">PyTorch NN package</a> contains many useful classes for creating computation graphs.\n",
        "<ul>\n",
        "<li> The class <a href=\"http://pytorch.org/docs/master/nn.html#module\">torch.nn.Module</a>: \n",
        "any new module must inherit from this class or its descendants (subclasses).\n",
        "</li>   \n",
        "<li> The `forward` method:  any class defining a module must implement the `forward(...)` method, which defines the transformation of inputs to outputs.</li>  \n",
        "<li> The class <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a>: this class implements a linear transformation. By default, it takes two parameters: \n",
        "    <ul>\n",
        "    <li>`in_features`: the size of the data at the input of the module. </li>\n",
        "    <li>`out_features`: the size of the data at the output of the module. </li>\n",
        "    </ul>\n",
        "</li>\n",
        "<li> The module <a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">`torch.nn.functional`</a>: \n",
        "it defines a set of functions that can be applied directly to any tensor. As examples, we have:\n",
        "    <ul>\n",
        "    <li> non-linear functions: sigmoid(...), tanh(...), relu(...), etc...</li> \n",
        "    <li> cost functions: mse_loss(...), nll(...., cross_entropy(...), etc ... </li> \n",
        "    <li> regularization functions: droupout(...), etc ... </li> \n",
        "    <li> ...</li> \n",
        "    </ul>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tscha6S-KIBB",
        "colab_type": "text"
      },
      "source": [
        "You need to complete the following methods:\n",
        "<ul>\n",
        "<li>The `__init__` method that defines the layers. </li>\n",
        "<li>The `forward(input)` method that returns the `output`. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NyQGwC-avkw",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xR5eBfIbavk0",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(12, 20) # Fully connected layer 1 : 12x20\n",
        "        self.fc2 = nn.Linear(20, 40) # Fully connected layer 2 : 20x40 \n",
        "        self.fc3 = nn.Linear(40, 20) # Fully connected layer 3 : 40x20\n",
        "        self.fc4 = nn.Linear(20, 2) # Fully connected layer 4 : 20x2\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        out = self.fc4(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OvLnHRZ5avk2"
      },
      "source": [
        "## Making predictions with a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uEXgJMDDavk3"
      },
      "source": [
        "Now, we are ready to test our neural network on randomly selected data.\n",
        "\n",
        "In PyTorch, a model has two different modes:\n",
        "    <ul>\n",
        "    <li> <b>train</b>: used during training, </li>\n",
        "    <li> <b>eval</b>: used during inference for model evaluation. </li>\n",
        "    </ul>\n",
        "The distinction is important since some modules behave differently according to this mode.\n",
        "We will use the <b>eval</b> mode in this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gzcABMezavk6",
        "outputId": "2a4c9152-a223-48d4-864b-888df61733c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Model definition\n",
        "neural_net = NeuralNet()\n",
        "neural_net = neural_net.to(device)\n",
        "\n",
        "# Eval mode activation\n",
        "neural_net = neural_net.eval()\n",
        "\n",
        "# Select the first 5 data points\n",
        "data, target = val_dataset[0:5]\n",
        "data = data.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "# Forward propagation of the data through the model\n",
        "output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
        "\n",
        "# Convert the logits into probabilities with softmax function\n",
        "output_proba = F.softmax(output, dim=1) # dim=1 -> for each sample\n",
        "\n",
        "# Printing the direct outputs\n",
        "print(output)\n",
        "# Printing the probability\n",
        "print(output_proba)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0991,  0.1567],\n",
            "        [-0.0273,  0.1651],\n",
            "        [-0.0041,  0.1696],\n",
            "        [-0.0114,  0.1881],\n",
            "        [-0.0435,  0.2095]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0.4364, 0.5636],\n",
            "        [0.4520, 0.5480],\n",
            "        [0.4567, 0.5433],\n",
            "        [0.4503, 0.5497],\n",
            "        [0.4371, 0.5629]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fVep0BElavlS"
      },
      "source": [
        "The rows define the output of the network, in terms of probabilities over two classes: <b>deceased</b> (first column) or <b>survived</b> (second column), for each of the five input data points. Let us take the label with maximum probability as the predicted label and compare it to the correct label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jV4No36qjdU",
        "outputId": "404ac617-3111-401d-a28f-a3737be36cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Printing predictions (class with the highest probability)\n",
        "_, prediction = torch.max(output_proba, dim=1)\n",
        "\n",
        "print('Model prediction')\n",
        "print(_)\n",
        "print(prediction)\n",
        "\n",
        "# Printing the real labels\n",
        "print(\"Actual data\")\n",
        "print(target)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prediction\n",
            "tensor([0.5636, 0.5480, 0.5433, 0.5497, 0.5629], device='cuda:0',\n",
            "       grad_fn=<MaxBackward0>)\n",
            "tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
            "Actual data\n",
            "tensor([0, 0, 0, 0, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SEIIjqOuqjdc"
      },
      "source": [
        "**Questions**\n",
        "\n",
        "1.   What would be a good way to measure the model performances?\n",
        "2.   How does our model perform?\n",
        "3.   Considering that the model is not trained on the dataset, do you see any problem with your selected measure?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTTlBikYwb-w",
        "colab_type": "text"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0uySA2TCavmD"
      },
      "source": [
        "## Define the cost function and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EkoobCLMavmE"
      },
      "source": [
        "### Cost function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qkX7uSXQavmF"
      },
      "source": [
        "We define the cost function according to the task we want to achieve.\n",
        "\n",
        "PyTorch offers <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">many ready-to-use cost functions</a>.\n",
        "\n",
        "For classification problems, the usual cost function is <b>cross-entropy</b>, and this is the one we will use in this tutorial. In PyTorch, it is defined by the function <a href=\"https://pytorch.org/docs/master/nn.functional.html#cross-entropy\">`torch.nn.functional.cross_entropy`</a>.  Cross entropy allows comparing a $p$ distribution with a reference distribution $t$. It attains its minimum when $t=p$. Its formula for calculating it between the prediction and the target is: $-\\sum_j t_{ij} \\log(p_{ij})$ where $p$ is the prediction, $t$ the target, $i$ the examples and $j$ the classes of the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FHnfYeS5avmF",
        "colab": {}
      },
      "source": [
        "def cost_function(prediction, target):\n",
        "    loss = F.cross_entropy(prediction, target)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vsx_cv9Wqjdj"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0hcZaIKtavmH"
      },
      "source": [
        "In Pytorch, thanks to the automatic differentiation mechanism <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">Autograd</a>, it is possible to automatically calculate the gradient of the cost function and backpropagate it through the computational graph.\n",
        "\n",
        "To do this, we only have to call the method `backward()` on the variable returned by the cost function, e.g., with\n",
        "\n",
        "`loss = cost_function(....)` <br>\n",
        "`loss.backward()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8YNo_ymYavmH"
      },
      "source": [
        "### Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y4AlX9TwavmH"
      },
      "source": [
        "PyTorch provides a <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\">set of optimization methods (`torch.optim`)</a> commonly used by the deep learning community. These methods include the following: \n",
        "<ul>\n",
        "<li><b>SGD</b> (Stochastic Gradient Descent) <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a></li>\n",
        "<li><b>Adam</b> (Adaptive Moment Estimation): a variant of the gradient descent method in which the learning rate is adjusted for each parameter. This adjustment is based on the estimation of the first and second moments of the gradients. This optimizer has demonstrated excellent performance compared to SGD on many benchmarks. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uam-a0_0qjdl"
      },
      "source": [
        "To be able to use an optimizer in PyTorch, we must instantiate it by passing the following elements:\n",
        "<ul>\n",
        "<li><b>The parameters of the model</b>: these are obtained using the method <b>parameters()</b> on the instantiated model. </li>\n",
        "<li><b>The learning rate (lr)</b>: this is the learning rate to be used to update parameters during the optimization process. </li>\n",
        "<li>There may be other parameters specific to the chosen optimizer.</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jt6_Qr6ravmI"
      },
      "source": [
        "PyTorch offers a simplified interface to interact with any optimizer:\n",
        "<ul>\n",
        "<li><b>zero_grad()</b>: Allows to reinitialize the gradients to zero at the beginning of an optimization step.</li>\n",
        "<li><b>step()</b>: Allows to perform an optimization step after a gradient backpropagation step.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fZ-lKExqavmI"
      },
      "source": [
        "We will use Adam with a lr of 0.001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WDMOziJTavmI",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = optim.Adam(neural_net.parameters(), lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OnFOAfdGqjdr"
      },
      "source": [
        "# How to train a model?\n",
        "First, we need some definitions:\n",
        "<ol>\n",
        "<li>\n",
        "<b>Epoch</b>: a complete pass over the entire training dataset.\n",
        "</li>\n",
        "<li>\n",
        "<b>Iteration</b>: an update of the model parameters. Many iterations can occur before the end of an epoch.\n",
        "</li>\n",
        "<li>\n",
        "<b>Mini-batch</b>: A subset of training data used to estimate the average of gradients. In other words, at each iteration, a mini-batch is used. \n",
        "</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LLXjNiDTavmK"
      },
      "source": [
        "## Creating the mini-batches\n",
        "PyTorch offers a utility called <b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> to load any dataset and automatically split it into mini-batches. During training, the data presented to the network should appear in a different order from one epoch to another. We will prepare the `DataLoader` for our three datasets (training, validation, and test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RGoQZSdqavmM",
        "colab": {}
      },
      "source": [
        "train_batch_size = 32  # number of data in a training batch.\n",
        "eval_batch_size = 32   # number of data in an batch.\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=eval_batch_size, shuffle=False)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=eval_batch_size, shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ia3ai-GvavmP"
      },
      "source": [
        "## Simple training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v9wNZrTnavmQ"
      },
      "source": [
        "Here we define our training procedure for an epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZyK9xCsZavmR",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, train_loader, optimizer, device):\n",
        "    \n",
        "    # activate the training mode\n",
        "    model.train()\n",
        "    \n",
        "    torch.set_grad_enabled(True)\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    # iteration over the mini-batches\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        \n",
        "        # transfer the data on the chosen device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # reinitialize the gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward propagation on the data\n",
        "        prediction = model(data)\n",
        "        \n",
        "        # compute the cost function w.r.t. the targets\n",
        "        loss = cost_function(prediction, target)\n",
        "        \n",
        "        # execute the backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # execute an optimization step\n",
        "        optimizer.step()\n",
        "        \n",
        "        # accumulate the loss\n",
        "        total_loss += loss.item()*len(data)\n",
        "        \n",
        "        # compute the number of correct predictions\n",
        "        _, pred_classes = torch.max(prediction, dim=1)        \n",
        "        correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()\n",
        "         \n",
        "        \n",
        "    # compute the average cost per epoch\n",
        "    mean_loss = total_loss/len(train_loader.dataset)\n",
        "    \n",
        "    # compute the accuracy\n",
        "    acc = correct / len(train_loader.dataset)\n",
        "        \n",
        "    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
        "        100. * acc))   \n",
        "    \n",
        "    # return the average loss and the accuracy\n",
        "    return mean_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PxG666rmavmU"
      },
      "source": [
        "## Evaluation procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vGexbWaHavmU"
      },
      "source": [
        "Here we define our model evaluation procedure.\n",
        "<br/>\n",
        "In addition to switching the model to **eval** mode, it is essential to disable the gradient calculation. \n",
        "<br/>\n",
        "To do this, PyTorch offers a set of context managers to <a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">locally disable/enable gradient calculation </a>:\n",
        "<ol>\n",
        "<li>\n",
        "`torch.no_grad()`: disable gradient calculation.\n",
        "</li>\n",
        "<li>\n",
        "`torch.enable_grad()`: enable gradient calculation.\n",
        "</li>\n",
        "<li>\n",
        "`torch.set_grad_enabled(bool)`: enable/disable gradient calculation.\n",
        "</li>\n",
        "</ol>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8gQj9W5LavmU",
        "colab": {}
      },
      "source": [
        "def evaluate(model, eval_loader, device):\n",
        "    \n",
        "    # activate the evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        # iterate over the batches\n",
        "        for batch_idx, (data, target) in enumerate(eval_loader):\n",
        "\n",
        "            # transfer the data on the chosen device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # forward propagation on the data\n",
        "            prediction = model(data)\n",
        "\n",
        "            # compute the cost function w.r.t. the targets\n",
        "            loss = cost_function(prediction, target)           \n",
        "\n",
        "\n",
        "            # accumulate the loss\n",
        "            total_loss += loss.item()*len(data)\n",
        "\n",
        "            # compute the number of correct predictions en sortie)\n",
        "            _, pred_classes = torch.max(prediction, dim=1) \n",
        "            correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()         \n",
        "          \n",
        "    \n",
        "    # compute the average cost per epoch\n",
        "    mean_loss = total_loss/len(eval_loader.dataset)\n",
        "    \n",
        "    # compute the accuracy\n",
        "    acc = correct / len(eval_loader.dataset)\n",
        "        \n",
        "    print('Eval:  Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        mean_loss, correct, len(eval_loader.dataset),\n",
        "        100. * acc)) \n",
        "    \n",
        "    # return the average loss and the accuracy\n",
        "    return mean_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fMUyZNxdavmW"
      },
      "source": [
        "## Checkpointing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lQLklQXAavmW"
      },
      "source": [
        "For training phases that require much time, it is recommended to save periodically the model parameters. This step is commonly referred to as <b>checkpointing</b>.\n",
        "\n",
        "PyTorch offers <a href=\"http://pytorch.org/docs/master/notes/serialization.html\">a simple mechanism</a> to perform this operation. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ld-Y2gF-avmX"
      },
      "source": [
        "We implement two methods here:\n",
        "<ul>\n",
        "<li> the first one for <b> saving </b> a model,</li>\n",
        "<li> the second for <b> loading </b> a model checkpoint. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dMmNpma2avmX",
        "colab": {}
      },
      "source": [
        "def save_model(epoch, model, path='./'):\n",
        "    \n",
        "    # creating the file name indexed by the epoch value\n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # saving the model parameters\n",
        "    torch.save(model.state_dict(), filename)\n",
        "    \n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ZptgqQRavmZ",
        "colab": {}
      },
      "source": [
        "def load_model(epoch, model, path='./'):\n",
        "    \n",
        "    # creating the file name indexed by the epoch value\n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # loading the parameters of the saved model\n",
        "    model.load_state_dict(torch.load(filename))\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ve8sOocWavma"
      },
      "source": [
        "It is also possible to save the status of the optimizer in PyTorch, which is very important when we want to resume training the model from a given backup. For more information, please consult <a href='https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3'>the following URL</a>. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8lcAP8-1avma"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "keMpyePsavmb",
        "outputId": "76cdfd4c-5c77-4c37-d7a5-a60931a21e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# maximum number of epoch\n",
        "numEpochs = 200\n",
        "\n",
        "# Saving frequency\n",
        "checkpoint_freq = 10\n",
        "\n",
        "# Directory for data backup\n",
        "path = '/content/drive/My Drive/IVADO_DL/'\n",
        "\n",
        "# Accumulators of average costs obtained per epoch\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Performance accumulators per epoch\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Model definition\n",
        "neural_net = NeuralNet()\n",
        "\n",
        "# Load the model on the chosen device\n",
        "neural_net = neural_net.to(device)\n",
        "\n",
        "# Optimizer definition\n",
        "optimizer = optim.Adam(neural_net.parameters(), lr=0.001) \n",
        "# optimizer = optim.SGD(neural_net.parameters(), lr=0.001) \n",
        "\n",
        "\n",
        "# Learning loop\n",
        "for epoch in range(1, numEpochs + 1):\n",
        "    \n",
        "    # train the model with the train dataset\n",
        "    train_loss, train_acc = train(epoch, neural_net, train_loader, optimizer, device)   \n",
        "    \n",
        "    # evaluate the model with the validation dataset\n",
        "    val_loss, val_acc = evaluate(neural_net, val_loader, device)       \n",
        "    \n",
        "    # Save the costs obtained\n",
        "    train_losses.append(train_loss)    \n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    # Save the performances\n",
        "    train_accuracies.append(train_acc)    \n",
        "    val_accuracies.append(val_acc)\n",
        "    \n",
        "    # Checkpoint\n",
        "    if epoch % checkpoint_freq ==0:\n",
        "        save_model(epoch, neural_net, path)\n",
        "\n",
        "# Save the model at the end of the training\n",
        "save_model(numEpochs, neural_net, path)\n",
        "    \n",
        "print(\"\\n\\n\\nOptimization ended.\\n\")    \n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.63986   Acc: 412/625 (65.920%)\n",
            "Eval:  Avg_Loss: 0.63053   Acc: 143/209 (68.421%)\n",
            "Train Epoch: 2   Avg_Loss: 0.62982   Acc: 420/625 (67.200%)\n",
            "Eval:  Avg_Loss: 0.62374   Acc: 141/209 (67.464%)\n",
            "Train Epoch: 3   Avg_Loss: 0.62401   Acc: 424/625 (67.840%)\n",
            "Eval:  Avg_Loss: 0.61636   Acc: 139/209 (66.507%)\n",
            "Train Epoch: 4   Avg_Loss: 0.62244   Acc: 419/625 (67.040%)\n",
            "Eval:  Avg_Loss: 0.61702   Acc: 140/209 (66.986%)\n",
            "Train Epoch: 5   Avg_Loss: 0.61164   Acc: 424/625 (67.840%)\n",
            "Eval:  Avg_Loss: 0.61092   Acc: 142/209 (67.943%)\n",
            "Train Epoch: 6   Avg_Loss: 0.61377   Acc: 423/625 (67.680%)\n",
            "Eval:  Avg_Loss: 0.62534   Acc: 141/209 (67.464%)\n",
            "Train Epoch: 7   Avg_Loss: 0.61308   Acc: 426/625 (68.160%)\n",
            "Eval:  Avg_Loss: 0.60691   Acc: 142/209 (67.943%)\n",
            "Train Epoch: 8   Avg_Loss: 0.61807   Acc: 420/625 (67.200%)\n",
            "Eval:  Avg_Loss: 0.63323   Acc: 140/209 (66.986%)\n",
            "Train Epoch: 9   Avg_Loss: 0.59888   Acc: 432/625 (69.120%)\n",
            "Eval:  Avg_Loss: 0.62437   Acc: 138/209 (66.029%)\n",
            "Train Epoch: 10   Avg_Loss: 0.61785   Acc: 428/625 (68.480%)\n",
            "Eval:  Avg_Loss: 0.61424   Acc: 142/209 (67.943%)\n",
            "Train Epoch: 11   Avg_Loss: 0.60476   Acc: 424/625 (67.840%)\n",
            "Eval:  Avg_Loss: 0.59720   Acc: 142/209 (67.943%)\n",
            "Train Epoch: 12   Avg_Loss: 0.59802   Acc: 431/625 (68.960%)\n",
            "Eval:  Avg_Loss: 0.59244   Acc: 142/209 (67.943%)\n",
            "Train Epoch: 13   Avg_Loss: 0.59424   Acc: 439/625 (70.240%)\n",
            "Eval:  Avg_Loss: 0.58818   Acc: 143/209 (68.421%)\n",
            "Train Epoch: 14   Avg_Loss: 0.58461   Acc: 439/625 (70.240%)\n",
            "Eval:  Avg_Loss: 0.57921   Acc: 144/209 (68.900%)\n",
            "Train Epoch: 15   Avg_Loss: 0.57694   Acc: 451/625 (72.160%)\n",
            "Eval:  Avg_Loss: 0.57516   Acc: 146/209 (69.856%)\n",
            "Train Epoch: 16   Avg_Loss: 0.57875   Acc: 454/625 (72.640%)\n",
            "Eval:  Avg_Loss: 0.56496   Acc: 147/209 (70.335%)\n",
            "Train Epoch: 17   Avg_Loss: 0.56143   Acc: 460/625 (73.600%)\n",
            "Eval:  Avg_Loss: 0.55041   Acc: 148/209 (70.813%)\n",
            "Train Epoch: 18   Avg_Loss: 0.55519   Acc: 469/625 (75.040%)\n",
            "Eval:  Avg_Loss: 0.55882   Acc: 153/209 (73.206%)\n",
            "Train Epoch: 19   Avg_Loss: 0.54106   Acc: 459/625 (73.440%)\n",
            "Eval:  Avg_Loss: 0.53122   Acc: 157/209 (75.120%)\n",
            "Train Epoch: 20   Avg_Loss: 0.52511   Acc: 482/625 (77.120%)\n",
            "Eval:  Avg_Loss: 0.52111   Acc: 155/209 (74.163%)\n",
            "Train Epoch: 21   Avg_Loss: 0.50783   Acc: 473/625 (75.680%)\n",
            "Eval:  Avg_Loss: 0.53858   Acc: 158/209 (75.598%)\n",
            "Train Epoch: 22   Avg_Loss: 0.52077   Acc: 478/625 (76.480%)\n",
            "Eval:  Avg_Loss: 0.50379   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 23   Avg_Loss: 0.49878   Acc: 481/625 (76.960%)\n",
            "Eval:  Avg_Loss: 0.54768   Acc: 157/209 (75.120%)\n",
            "Train Epoch: 24   Avg_Loss: 0.50828   Acc: 485/625 (77.600%)\n",
            "Eval:  Avg_Loss: 0.49655   Acc: 160/209 (76.555%)\n",
            "Train Epoch: 25   Avg_Loss: 0.47180   Acc: 495/625 (79.200%)\n",
            "Eval:  Avg_Loss: 0.49760   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 26   Avg_Loss: 0.47016   Acc: 493/625 (78.880%)\n",
            "Eval:  Avg_Loss: 0.48786   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 27   Avg_Loss: 0.46341   Acc: 486/625 (77.760%)\n",
            "Eval:  Avg_Loss: 0.49655   Acc: 157/209 (75.120%)\n",
            "Train Epoch: 28   Avg_Loss: 0.48163   Acc: 481/625 (76.960%)\n",
            "Eval:  Avg_Loss: 0.50639   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 29   Avg_Loss: 0.46151   Acc: 494/625 (79.040%)\n",
            "Eval:  Avg_Loss: 0.49044   Acc: 158/209 (75.598%)\n",
            "Train Epoch: 30   Avg_Loss: 0.47594   Acc: 488/625 (78.080%)\n",
            "Eval:  Avg_Loss: 0.50472   Acc: 161/209 (77.033%)\n",
            "Train Epoch: 31   Avg_Loss: 0.46191   Acc: 490/625 (78.400%)\n",
            "Eval:  Avg_Loss: 0.50220   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 32   Avg_Loss: 0.45459   Acc: 494/625 (79.040%)\n",
            "Eval:  Avg_Loss: 0.48961   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 33   Avg_Loss: 0.44684   Acc: 500/625 (80.000%)\n",
            "Eval:  Avg_Loss: 0.48650   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 34   Avg_Loss: 0.44857   Acc: 495/625 (79.200%)\n",
            "Eval:  Avg_Loss: 0.48087   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 35   Avg_Loss: 0.44333   Acc: 499/625 (79.840%)\n",
            "Eval:  Avg_Loss: 0.50035   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 36   Avg_Loss: 0.45003   Acc: 500/625 (80.000%)\n",
            "Eval:  Avg_Loss: 0.48472   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 37   Avg_Loss: 0.43965   Acc: 493/625 (78.880%)\n",
            "Eval:  Avg_Loss: 0.48986   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 38   Avg_Loss: 0.43716   Acc: 500/625 (80.000%)\n",
            "Eval:  Avg_Loss: 0.48512   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 39   Avg_Loss: 0.44266   Acc: 500/625 (80.000%)\n",
            "Eval:  Avg_Loss: 0.49452   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 40   Avg_Loss: 0.43559   Acc: 501/625 (80.160%)\n",
            "Eval:  Avg_Loss: 0.47710   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 41   Avg_Loss: 0.42954   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.48428   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 42   Avg_Loss: 0.43342   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.48170   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 43   Avg_Loss: 0.43150   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.49092   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 44   Avg_Loss: 0.43313   Acc: 503/625 (80.480%)\n",
            "Eval:  Avg_Loss: 0.47874   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 45   Avg_Loss: 0.46247   Acc: 491/625 (78.560%)\n",
            "Eval:  Avg_Loss: 0.51729   Acc: 161/209 (77.033%)\n",
            "Train Epoch: 46   Avg_Loss: 0.44128   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.51043   Acc: 159/209 (76.077%)\n",
            "Train Epoch: 47   Avg_Loss: 0.43741   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.49275   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 48   Avg_Loss: 0.44988   Acc: 504/625 (80.640%)\n",
            "Eval:  Avg_Loss: 0.49300   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 49   Avg_Loss: 0.42215   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.47672   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 50   Avg_Loss: 0.42525   Acc: 506/625 (80.960%)\n",
            "Eval:  Avg_Loss: 0.48579   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 51   Avg_Loss: 0.42325   Acc: 508/625 (81.280%)\n",
            "Eval:  Avg_Loss: 0.48481   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 52   Avg_Loss: 0.42183   Acc: 504/625 (80.640%)\n",
            "Eval:  Avg_Loss: 0.47821   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 53   Avg_Loss: 0.42296   Acc: 505/625 (80.800%)\n",
            "Eval:  Avg_Loss: 0.48130   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 54   Avg_Loss: 0.43853   Acc: 506/625 (80.960%)\n",
            "Eval:  Avg_Loss: 0.51365   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 55   Avg_Loss: 0.43408   Acc: 503/625 (80.480%)\n",
            "Eval:  Avg_Loss: 0.49688   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 56   Avg_Loss: 0.42750   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.48683   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 57   Avg_Loss: 0.41738   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.47288   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 58   Avg_Loss: 0.41126   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.48153   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 59   Avg_Loss: 0.43658   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.53520   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 60   Avg_Loss: 0.46866   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.49165   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 61   Avg_Loss: 0.42988   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.48221   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 62   Avg_Loss: 0.42138   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.49028   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 63   Avg_Loss: 0.41083   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.47647   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 64   Avg_Loss: 0.40936   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.47641   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 65   Avg_Loss: 0.41424   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.48579   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 66   Avg_Loss: 0.41782   Acc: 501/625 (80.160%)\n",
            "Eval:  Avg_Loss: 0.47188   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 67   Avg_Loss: 0.40727   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.47693   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 68   Avg_Loss: 0.40604   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.47456   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 69   Avg_Loss: 0.40447   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.49575   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 70   Avg_Loss: 0.41343   Acc: 506/625 (80.960%)\n",
            "Eval:  Avg_Loss: 0.49586   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 71   Avg_Loss: 0.40742   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.48331   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 72   Avg_Loss: 0.40936   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.48109   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 73   Avg_Loss: 0.40636   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.48317   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 74   Avg_Loss: 0.39818   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.48095   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 75   Avg_Loss: 0.40309   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.48391   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 76   Avg_Loss: 0.40552   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.48004   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 77   Avg_Loss: 0.41571   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.48292   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 78   Avg_Loss: 0.40631   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.48418   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 79   Avg_Loss: 0.39736   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.48038   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 80   Avg_Loss: 0.40723   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.48872   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 81   Avg_Loss: 0.40752   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.49284   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 82   Avg_Loss: 0.40013   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.48123   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 83   Avg_Loss: 0.39836   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.49069   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 84   Avg_Loss: 0.40224   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.48171   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 85   Avg_Loss: 0.40338   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.49391   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 86   Avg_Loss: 0.39867   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.49151   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 87   Avg_Loss: 0.40679   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.48455   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 88   Avg_Loss: 0.40189   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.51799   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 89   Avg_Loss: 0.44737   Acc: 499/625 (79.840%)\n",
            "Eval:  Avg_Loss: 0.56724   Acc: 159/209 (76.077%)\n",
            "Train Epoch: 90   Avg_Loss: 0.43435   Acc: 505/625 (80.800%)\n",
            "Eval:  Avg_Loss: 0.51031   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 91   Avg_Loss: 0.40218   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.47656   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 92   Avg_Loss: 0.39128   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.47966   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 93   Avg_Loss: 0.39174   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.51260   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 94   Avg_Loss: 0.41861   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.53079   Acc: 161/209 (77.033%)\n",
            "Train Epoch: 95   Avg_Loss: 0.44444   Acc: 497/625 (79.520%)\n",
            "Eval:  Avg_Loss: 0.56114   Acc: 160/209 (76.555%)\n",
            "Train Epoch: 96   Avg_Loss: 0.44414   Acc: 495/625 (79.200%)\n",
            "Eval:  Avg_Loss: 0.53891   Acc: 161/209 (77.033%)\n",
            "Train Epoch: 97   Avg_Loss: 0.43122   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.50780   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 98   Avg_Loss: 0.40106   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.51407   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 99   Avg_Loss: 0.40152   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.48159   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 100   Avg_Loss: 0.39439   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.48848   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 101   Avg_Loss: 0.39214   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.49969   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 102   Avg_Loss: 0.39716   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.49702   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 103   Avg_Loss: 0.39275   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.47265   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 104   Avg_Loss: 0.39044   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.48199   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 105   Avg_Loss: 0.38762   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.48932   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 106   Avg_Loss: 0.39039   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.48872   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 107   Avg_Loss: 0.38481   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.48275   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 108   Avg_Loss: 0.38650   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.48398   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 109   Avg_Loss: 0.38572   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.48219   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 110   Avg_Loss: 0.39600   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.49286   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 111   Avg_Loss: 0.38380   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.48556   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 112   Avg_Loss: 0.38629   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.50473   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 113   Avg_Loss: 0.38515   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.49852   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 114   Avg_Loss: 0.38524   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.49529   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 115   Avg_Loss: 0.38404   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.48973   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 116   Avg_Loss: 0.38940   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.49990   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 117   Avg_Loss: 0.40124   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.49503   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 118   Avg_Loss: 0.38342   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.49092   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 119   Avg_Loss: 0.38867   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.48189   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 120   Avg_Loss: 0.39587   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.49970   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 121   Avg_Loss: 0.39440   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.49823   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 122   Avg_Loss: 0.38783   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.48728   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 123   Avg_Loss: 0.38175   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.49036   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 124   Avg_Loss: 0.38176   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.49770   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 125   Avg_Loss: 0.38510   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.49473   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 126   Avg_Loss: 0.38800   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.52743   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 127   Avg_Loss: 0.39160   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.48546   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 128   Avg_Loss: 0.37853   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51302   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 129   Avg_Loss: 0.39453   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.51586   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 130   Avg_Loss: 0.40173   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.49641   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 131   Avg_Loss: 0.39324   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.49840   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 132   Avg_Loss: 0.37581   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.49949   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 133   Avg_Loss: 0.37996   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.50876   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 134   Avg_Loss: 0.37961   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.49296   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 135   Avg_Loss: 0.37558   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.57132   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 136   Avg_Loss: 0.39811   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.49410   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 137   Avg_Loss: 0.38393   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.50219   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 138   Avg_Loss: 0.37936   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.49761   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 139   Avg_Loss: 0.37451   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.49889   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 140   Avg_Loss: 0.38336   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.48938   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 141   Avg_Loss: 0.37385   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.50287   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 142   Avg_Loss: 0.38751   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.53292   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 143   Avg_Loss: 0.37547   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.50701   Acc: 174/209 (83.254%)\n",
            "Train Epoch: 144   Avg_Loss: 0.37240   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.49874   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 145   Avg_Loss: 0.37173   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.50836   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 146   Avg_Loss: 0.37251   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.50349   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 147   Avg_Loss: 0.38482   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.51314   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 148   Avg_Loss: 0.36882   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.51153   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 149   Avg_Loss: 0.37203   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.50741   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 150   Avg_Loss: 0.38129   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.54559   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 151   Avg_Loss: 0.37521   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.49891   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 152   Avg_Loss: 0.36957   Acc: 527/625 (84.320%)\n",
            "Eval:  Avg_Loss: 0.51073   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 153   Avg_Loss: 0.37244   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.50734   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 154   Avg_Loss: 0.37123   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.52534   Acc: 174/209 (83.254%)\n",
            "Train Epoch: 155   Avg_Loss: 0.37037   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.50773   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 156   Avg_Loss: 0.39053   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.52687   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 157   Avg_Loss: 0.37225   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51188   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 158   Avg_Loss: 0.37247   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.56430   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 159   Avg_Loss: 0.38521   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.53368   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 160   Avg_Loss: 0.37899   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.51224   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 161   Avg_Loss: 0.38152   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.52984   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 162   Avg_Loss: 0.37566   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51671   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 163   Avg_Loss: 0.36769   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.51274   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 164   Avg_Loss: 0.37300   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.51740   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 165   Avg_Loss: 0.37034   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.51645   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 166   Avg_Loss: 0.37339   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.50192   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 167   Avg_Loss: 0.36920   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.50809   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 168   Avg_Loss: 0.36800   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.52531   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 169   Avg_Loss: 0.36768   Acc: 530/625 (84.800%)\n",
            "Eval:  Avg_Loss: 0.51769   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 170   Avg_Loss: 0.36802   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.50726   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 171   Avg_Loss: 0.36471   Acc: 528/625 (84.480%)\n",
            "Eval:  Avg_Loss: 0.51719   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 172   Avg_Loss: 0.36647   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.51288   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 173   Avg_Loss: 0.36708   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.54386   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 174   Avg_Loss: 0.36670   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.52226   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 175   Avg_Loss: 0.37575   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.53168   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 176   Avg_Loss: 0.37961   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.53916   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 177   Avg_Loss: 0.37118   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51908   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 178   Avg_Loss: 0.36749   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.52303   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 179   Avg_Loss: 0.35620   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.54379   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 180   Avg_Loss: 0.37936   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.52288   Acc: 174/209 (83.254%)\n",
            "Train Epoch: 181   Avg_Loss: 0.36323   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.52469   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 182   Avg_Loss: 0.36308   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.52866   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 183   Avg_Loss: 0.35521   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.53209   Acc: 173/209 (82.775%)\n",
            "Train Epoch: 184   Avg_Loss: 0.38128   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51441   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 185   Avg_Loss: 0.36129   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.52088   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 186   Avg_Loss: 0.37065   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.54024   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 187   Avg_Loss: 0.37793   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.53870   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 188   Avg_Loss: 0.36340   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.53946   Acc: 171/209 (81.818%)\n",
            "Train Epoch: 189   Avg_Loss: 0.41999   Acc: 498/625 (79.680%)\n",
            "Eval:  Avg_Loss: 0.56539   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 190   Avg_Loss: 0.39581   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.54852   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 191   Avg_Loss: 0.36745   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.51737   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 192   Avg_Loss: 0.36335   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.51780   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 193   Avg_Loss: 0.35984   Acc: 528/625 (84.480%)\n",
            "Eval:  Avg_Loss: 0.50944   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 194   Avg_Loss: 0.36063   Acc: 528/625 (84.480%)\n",
            "Eval:  Avg_Loss: 0.55411   Acc: 169/209 (80.861%)\n",
            "Train Epoch: 195   Avg_Loss: 0.37550   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.54010   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 196   Avg_Loss: 0.35938   Acc: 532/625 (85.120%)\n",
            "Eval:  Avg_Loss: 0.54037   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 197   Avg_Loss: 0.37377   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.52704   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 198   Avg_Loss: 0.35719   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.51729   Acc: 170/209 (81.340%)\n",
            "Train Epoch: 199   Avg_Loss: 0.36419   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.54045   Acc: 172/209 (82.297%)\n",
            "Train Epoch: 200   Avg_Loss: 0.37650   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.53360   Acc: 169/209 (80.861%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "86OZRLrjavmd"
      },
      "source": [
        "## Interpreting the output of the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mklvQruYavme",
        "outputId": "d2edede4-0b4b-4e2a-d2ea-b216354e13bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Activate the evaluation mode\n",
        "neural_net = neural_net.eval()\n",
        "\n",
        "# Select the first 10 data points of the validation set\n",
        "data, target = val_dataset[0:10]\n",
        "data = data.to(device)\n",
        "\n",
        "# Executing the neural network\n",
        "output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
        "\n",
        "# Transform the output into a probability distribution with a softmax function\n",
        "output_proba = F.softmax(output, dim=1) # dim=1 -> for each sample\n",
        "\n",
        "\n",
        "# Print the probability\n",
        "print(output)\n",
        "print(output_proba)\n",
        "print(\"REAL:\")\n",
        "print(target)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3019, -1.6501],\n",
            "        [-0.3969, -0.4270],\n",
            "        [-0.4038, -0.1794],\n",
            "        [-0.5407, -0.0449],\n",
            "        [-0.1907, -0.5694],\n",
            "        [ 0.5905, -1.0280],\n",
            "        [ 0.1778, -1.0003],\n",
            "        [-0.4616, -0.4043],\n",
            "        [-2.7787,  2.3400],\n",
            "        [-2.4006,  3.0122]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[0.8757, 0.1243],\n",
            "        [0.5075, 0.4925],\n",
            "        [0.4441, 0.5559],\n",
            "        [0.3785, 0.6215],\n",
            "        [0.5936, 0.4064],\n",
            "        [0.8346, 0.1654],\n",
            "        [0.7646, 0.2354],\n",
            "        [0.4857, 0.5143],\n",
            "        [0.0059, 0.9941],\n",
            "        [0.0044, 0.9956]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "REAL:\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RvIEqKt0qjeT",
        "outputId": "6a4ef4b7-61a0-4a08-83ba-134f5711d1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# For each example, retrieve the class with the highest probability.\n",
        "_, prediction = torch.max(output_proba, dim=1)\n",
        "\n",
        "print(\"Model predictions\")\n",
        "print(prediction)\n",
        "\n",
        "print(\"Targets\")\n",
        "print(target)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model predictions\n",
            "tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
            "Targets\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ1EKgnnMxUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "99a239f2-56cc-40d7-ddb8-ebe5ffb80fed"
      },
      "source": [
        "print(train_losses)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6398628041744232, 0.6298152451515198, 0.6240142078399659, 0.6224418734550476, 0.6116425679206848, 0.6137747161865235, 0.6130768028259277, 0.6180725090026855, 0.5988823808670044, 0.6178476811408996, 0.6047561731338501, 0.5980249933242798, 0.5942432779312133, 0.5846096356391907, 0.5769428328514099, 0.578748664522171, 0.5614303536415101, 0.5551910374164581, 0.5410552395820618, 0.5251126284599305, 0.5078349461555481, 0.5207674872398377, 0.498782288646698, 0.5082758500099183, 0.4718041365146637, 0.4701589783191681, 0.4634090138912201, 0.48163444452285764, 0.46150743503570557, 0.4759441283226013, 0.46190902390480043, 0.4545929161071777, 0.44683667726516724, 0.4485681179523468, 0.44332820701599124, 0.4500289608001709, 0.43964652652740477, 0.43716421928405763, 0.44266166381835936, 0.4355876050949097, 0.4295447675704956, 0.43342325019836425, 0.43150126962661745, 0.4331277132034302, 0.4624728916168213, 0.44127604694366457, 0.4374103538513184, 0.4498801263809204, 0.42214690036773683, 0.42525214343070983, 0.4232546558380127, 0.4218296718120575, 0.42295991501808167, 0.4385272387981415, 0.43408187325000763, 0.42750153245925904, 0.41738280997276306, 0.4112552968978882, 0.43658177547454835, 0.4686566390514374, 0.4298793360710144, 0.42138479766845705, 0.41083388671875, 0.4093625856399536, 0.414241780424118, 0.4178170901298523, 0.4072713722229004, 0.40604208421707155, 0.4044740299224854, 0.41343106112480166, 0.4074221648693085, 0.4093617703437805, 0.4063628492355347, 0.3981797096729279, 0.4030919780254364, 0.4055247371673584, 0.41571258192062377, 0.4063074240207672, 0.39736451787948607, 0.4072276348590851, 0.4075240386009216, 0.40012920265197754, 0.3983614102363586, 0.4022406231880188, 0.4033823246002197, 0.3986728485107422, 0.4067918911933899, 0.401885422039032, 0.4473731267929077, 0.4343478222370148, 0.402182559967041, 0.39128476896286013, 0.3917417357444763, 0.41861480379104615, 0.44444161005020144, 0.4441443090438843, 0.43122194471359254, 0.4010626447200775, 0.4015247185230255, 0.3943896250247955, 0.3921379715442658, 0.3971642768859863, 0.39275461111068727, 0.3904396570205688, 0.38761558475494384, 0.39038844079971313, 0.3848116635799408, 0.38650365438461304, 0.3857207058906555, 0.39599671778678897, 0.38380229439735414, 0.3862918665409088, 0.3851485034942627, 0.3852394565105438, 0.384041246342659, 0.38939845905303955, 0.40124061307907105, 0.3834218138217926, 0.38867042093276977, 0.39586816883087156, 0.3944036074638367, 0.38782967953681946, 0.3817489182472229, 0.38175929923057556, 0.38510418663024903, 0.3880030273914337, 0.39159538407325745, 0.3785345346212387, 0.3945331007003784, 0.4017312426567078, 0.39324160141944886, 0.3758126085042954, 0.37995706453323363, 0.3796086354255676, 0.3755807207107544, 0.3981109603881836, 0.3839283706188202, 0.37935618081092837, 0.37451210522651673, 0.383361994600296, 0.37385019369125366, 0.38750543575286867, 0.37547464661598207, 0.3724030895233154, 0.371729697227478, 0.3725061227321625, 0.38481529178619384, 0.36881683931350706, 0.37202629766464235, 0.3812933990478516, 0.375214986371994, 0.3695733855247498, 0.3724437402248383, 0.3712289452314377, 0.3703702293872833, 0.3905349671840668, 0.3722539586544037, 0.37247307970523835, 0.3852084587574005, 0.3789948281288147, 0.38151979744434356, 0.3756568560123444, 0.3676915565013886, 0.37299842343330386, 0.370342764043808, 0.3733896710395813, 0.369200190448761, 0.36799717164039614, 0.3676758608818054, 0.36802425577640535, 0.3647050887107849, 0.36646533002853393, 0.3670783495426178, 0.3667006655693054, 0.3757477252006531, 0.3796060919761658, 0.3711772904872894, 0.36749478602409363, 0.35619850454330443, 0.3793559914588928, 0.36322662739753725, 0.36307645606994626, 0.35521242191791536, 0.38128126990795136, 0.36128706769943236, 0.3706507875919342, 0.3779330729484558, 0.3633953956604004, 0.4199867931365967, 0.39580981798172, 0.3674543338775635, 0.36335295271873475, 0.3598392873764038, 0.3606255620002747, 0.37549554200172425, 0.3593750126838684, 0.3737686191558838, 0.35718660879135133, 0.36419090719223024, 0.3764988742351532]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V11J3Jihavmy"
      },
      "source": [
        "## Visualizing of the learning curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j9_9C_tXavmz"
      },
      "source": [
        "The visualization of the learning curve allows to detect possible problems that may have occurred during learning, for example, overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iNcbpl0tavm0",
        "outputId": "713d50f2-f268-4ad4-9e42-3fda1b42cd0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "x = list(range(len(train_losses)))\n",
        "\n",
        "ax = plt.subplot(111)\n",
        "plt.plot(x, train_losses, 'r', label=\"Train\")\n",
        "plt.plot(x, val_losses, 'g', label=\"Validation\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Cross-entropy loss')\n",
        "plt.grid()\n",
        "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
        "leg.get_frame().set_alpha(0.99)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g-VGQ2pMavm4",
        "outputId": "088a1a9d-c44b-44b9-ac0d-5831c9725095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "x = list(range(len(train_accuracies)))\n",
        "\n",
        "ax = plt.subplot(111)\n",
        "plt.plot(x, train_accuracies, 'r', label=\"Train\")\n",
        "plt.plot(x, val_accuracies, 'g', label=\"Validation\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid()\n",
        "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
        "leg.get_frame().set_alpha(0.99)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8oktkpkuqjet"
      },
      "source": [
        "**Questions**:\n",
        "\n",
        "*   What do you observe in the previous graphs?\n",
        "*   At which epoch is it interesting to retrieve the model parameters for inference?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwhRt39yzug-",
        "colab_type": "text"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XK_eUsq3avm8"
      },
      "source": [
        "# How to evaluate a model on the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4UREO5elavm8"
      },
      "source": [
        "We can finally evaluate our model on our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pPWvDM-qavm8",
        "outputId": "ce6339a4-9c6f-484f-c850-c1aa8a4bb704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(neural_net, test_loader, device)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.50145   Acc: 160/209 (76.555%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EvP_-KUwqjez"
      },
      "source": [
        "**Questions**:\n",
        "\n",
        "a) Compare validation and test metrics. <br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov4CKUFh5tun",
        "colab_type": "text"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfykotIrJV0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}